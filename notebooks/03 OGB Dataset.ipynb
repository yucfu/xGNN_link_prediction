{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "713fc052",
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('../src/')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f537770b",
   "metadata": {},
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "from torch_geometric import seed_everything\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from models import LinkGIN, LinkGCN, LinkSAGE, DeepVGAE\n",
    "from decoders import InnerProductDecoder, CosineDecoder\n",
    "from explainers import gnnexplainer, ig, deconvolution, backprop\n",
    "from metrics import deletion_curve_edges, deletion_curve_features, linear_area_score\n",
    "from utils import ws_graph_model, sbm_graph_model, get_computation_graph_as_nx\n",
    "from utils import get_explanation\n",
    "from plotting import visualize_explanation\n",
    "\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from torch_geometric.nn import APPNP, MessagePassing"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fde54314",
   "metadata": {},
   "source": [
    "process the dataset from ogb\n",
    "\n",
    "https://ogb.stanford.edu/docs/linkprop/\n",
    "\n",
    "Reference: \n",
    "\n",
    "https://github.com/snap-stanford/ogb/blob/master/examples/linkproppred/collab/gnn.py\n",
    "\n",
    "https://medium.com/@xjurajkmec/pairwise-learning-for-neural-link-prediction-f1d16a0d28f6\n",
    "\n",
    "https://github.com/lustoo/OGB_link_prediction/blob/main/DDI/link_pred_ddi_graphsage_edge.py#L173\n",
    "\n",
    "\n",
    "图基准数据集（Open Graph Benchmark, OGB）\n",
    "https://zhuanlan.zhihu.com/p/358995864?utm_id=0\n",
    "\n",
    "1. ogbl-collab\n",
    "- Nodes: 235,868\n",
    "- Edges: 1,285,465\n",
    "\n",
    "2. ogbl-ddi\n",
    "- Nodes: 4,267\n",
    "- Edges: 1,285,465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22720827",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "graph_model = 'ogbl-collab'  # ['cora', 'ogbl-collab']\n",
    "model_name = 'gcn'  # ['gin', 'gcn', 'sage', 'vgae']\n",
    "explainer = 'gnnexplainer'  # ['random', 'ig', 'gnnexplainer', 'deconvolution', 'grad', 'empty', 'pgmexplainer']\n",
    "decoder = 'inner'  # ['inner', 'cosine']\n",
    "edge_noise_type = 'bernoulli_whole'  # ['bernoulli_whole', 'bernoulli_computation', 'kde']\n",
    "load_model = True\n",
    "seed = 0\n",
    "\n",
    "if model_name == 'vgae':\n",
    "    sigmoid = False\n",
    "else:\n",
    "    sigmoid = True\n",
    "\n",
    "if model_name == 'vgae':\n",
    "    return_type = 'probs'\n",
    "    from train_test import train_vgae as train\n",
    "    from train_test import test_vgae as test\n",
    "else:\n",
    "    return_type = 'raw'\n",
    "    from train_test import train\n",
    "    from train_test import test\n",
    "    \n",
    "print(seed, graph_model, model_name, explainer, decoder, return_type)  \n",
    "\n",
    "output_folder = f\"../outputs/{graph_model}/{model_name}/{explainer}/\"\n",
    "model_folder = f\"../outputs/{graph_model}/{model_name}/\""
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbb0aa3d",
   "metadata": {},
   "source": [
    "seed_everything(seed)\n",
    "\n",
    "if graph_model in ['cora']:\n",
    "    \n",
    "    transform = T.Compose([\n",
    "        T.NormalizeFeatures(),\n",
    "        T.ToDevice(device),\n",
    "        T.RandomLinkSplit(num_val=0.0, num_test=0.2, is_undirected=True),\n",
    "    ])\n",
    "\n",
    "    dataset = graph_model.capitalize()\n",
    "    path = osp.join('../', 'data', 'Planetoid')\n",
    "    dataset = Planetoid(path, dataset, transform=transform)\n",
    "    # train_data, val_data, test_data = dataset[0]\n",
    "    train_data, _, test_data = dataset[0]\n",
    "\n",
    "elif graph_model in ['ogbl-collab']:\n",
    "    \n",
    "    \n",
    "#     from ogb.linkproppred import PygLinkPropPredDataset\n",
    "\n",
    "#     dataset = PygLinkPropPredDataset(name='ogbl-collab') \n",
    "#     split_edge = dataset.get_edge_split()\n",
    "#     train_edge, valid_edge, test_edge = split_edge[\"train\"], split_edge[\"valid\"], split_edge[\"test\"]\n",
    "#     graph = dataset[0] # pyg graph object containing only training edges"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9800b53f",
   "metadata": {},
   "source": [
    "device = 0\n",
    "device = f'cuda:{device}' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device)\n",
    "device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfc9623",
   "metadata": {},
   "source": [
    "from ogb.linkproppred import PygLinkPropPredDataset\n",
    "import torch_geometric.utils as U\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "dataset = PygLinkPropPredDataset(name='ogbl-collab')\n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "data = dataset[0]\n",
    "\n",
    "edge_index = data.edge_index\n",
    "data.edge_weight = data.edge_weight.view(-1).to(torch.float)\n",
    "data = T.ToSparseTensor()(data)\n",
    "data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "62a53a27",
   "metadata": {},
   "source": [
    "# torch.concat([split_edge['valid']['edge'], split_edge['train']['edge']], dim=0).shape\n",
    "\n",
    "# new_edges = torch.concat([split_edge['valid']['edge'], split_edge['train']['edge']], dim=0)\n",
    "# new_weights = torch.concat([split_edge['valid']['weight'], split_edge['train']['weight']])\n",
    "# # new_edges, new_weights = U.coalesce(new_edges.t(), new_weights)\n",
    "# split_edge['train']['edge'] = new_edges.t()\n",
    "# split_edge['train']['weight'] = new_weights"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c0e120b5",
   "metadata": {},
   "source": [
    "# new_edges, new_weights = U.to_undirected(split_edge['train']['edge'].t(), split_edge['train']['weight'])\n",
    "# new_weights = new_weights.unsqueeze(-1)\n",
    "# data.edge_index = new_edges\n",
    "# data.edge_weight = new_weights\n",
    "\n",
    "# # data = T.ToSparseTensor()(data)\n",
    "# # data.adj_t = data.adj_t.float()\n",
    "# # row, col, data.edge_weight = data.adj_t.t().coo()\n",
    "# # data.edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "# data"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79231df4",
   "metadata": {},
   "source": [
    "# # include validation edges in the original training set as the new training set\n",
    "\n",
    "# data = train_data.clone()\n",
    "# edge_split = deepcopy(edge_split)\n",
    "\n",
    "# # Concatenate train and validation splits, remove duplicities.\n",
    "# new_edges = torch.concat([edge_split['valid']['edge'], edge_split['train']['edge']], dim=0)\n",
    "# new_edges = U.coalesce(new_edges.t())\n",
    "# edge_split['train']['edge'] = new_edges.t()\n",
    "\n",
    "# # Update the data object.\n",
    "# # Create a new sparse adjacency matrix from the new training split.\n",
    "# new_edges = U.to_undirected(edge_split['train']['edge'].t())\n",
    "\n",
    "# data.edge_index = new_edges\n",
    "\n",
    "# data = T.ToSparseTensor()(data)\n",
    "# data.adj_t = data.adj_t.float()\n",
    "# row, col, _ = data.adj_t.t().coo()\n",
    "# data.edge_index = torch.stack([row, col], dim=0)\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c80f21",
   "metadata": {},
   "source": [
    "# from torch_sparse import SparseTensor\n",
    "\n",
    "split_edge = dataset.get_edge_split()\n",
    "\n",
    "use_valedges_as_input = False\n",
    "\n",
    "# Use training + validation edges for inference on test set.\n",
    "if use_valedges_as_input:\n",
    "    val_edge_index = split_edge['valid']['edge'].t()\n",
    "    full_edge_index = torch.cat([edge_index, val_edge_index], dim=-1)\n",
    "    data.full_adj_t = SparseTensor.from_edge_index(full_edge_index).t()\n",
    "    data.full_adj_t = data.full_adj_t.to_symmetric()\n",
    "else:\n",
    "    data.full_adj_t = data.adj_t\n",
    "\n",
    "data = data.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16b2d32a",
   "metadata": {},
   "source": [
    "dataset[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9201daac",
   "metadata": {},
   "source": [
    "class GCN_OGB(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(GCN_OGB, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for conv in self.convs[:-1]:\n",
    "            x = conv(x, adj_t)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x\n",
    "    \n",
    "class LinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers,\n",
    "                 dropout):\n",
    "        super(LinkPredictor, self).__init__()\n",
    "\n",
    "        self.lins = torch.nn.ModuleList()\n",
    "        self.lins.append(torch.nn.Linear(in_channels, hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "        self.lins.append(torch.nn.Linear(hidden_channels, out_channels))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for lin in self.lins:\n",
    "            lin.reset_parameters()\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        x = x_i * x_j\n",
    "        for lin in self.lins[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.lins[-1](x)\n",
    "        return torch.sigmoid(x\n",
    "                             \n",
    "                             \n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726bd9f0",
   "metadata": {},
   "source": [
    "class LinkGCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, sim='inner', sigmoid=False):\n",
    "        super().__init__()\n",
    "\n",
    "        self.sigmoid = sigmoid\n",
    "\n",
    "        if sim == 'inner':\n",
    "            self.decoder = InnerProductDecoder()\n",
    "        elif sim == 'cosine':\n",
    "            self.decoder = CosineDecoder()\n",
    "\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encoder(self, x, edge_index, edge_weight=None):\n",
    "        x = self.conv1(x, edge_index, edge_weight).relu()\n",
    "        x = self.conv2(x, edge_index, edge_weight)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x, edge_index, edge_weight=None):\n",
    "\n",
    "        return self.encoder(x, edge_index, edge_weight)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "\n",
    "        return self.decoder(z, edge_label_index, sigmoid=self.sigmoid)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "\n",
    "        return self.decoder.forward_all(z, sigmoid=self.sigmoid)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_label_index, edge_weight=None):\n",
    "        z = self.encode(x, edge_index, edge_weight)\n",
    "        return self.decode(z, edge_label_index).view(-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82c41f3",
   "metadata": {},
   "source": [
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv\n",
    "\n",
    "# class LinkGCNCombined(torch.nn.Module):\n",
    "#     def __init__(self, in_channels, hidden_channels, out_channels, num_layers, dropout, sim='inner', sigmoid=True):\n",
    "#         super().__init__()\n",
    "#         self.sigmoid = sigmoid\n",
    "\n",
    "#         # Initialize GCN layers\n",
    "#         self.convs = torch.nn.ModuleList()\n",
    "#         self.convs.append(GCNConv(in_channels, hidden_channels))\n",
    "#         for _ in range(num_layers - 2):\n",
    "#             self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
    "#         self.convs.append(GCNConv(hidden_channels, out_channels))\n",
    "\n",
    "#         # Initialize Link Predictor layers\n",
    "#         self.lins = torch.nn.ModuleList()\n",
    "#         self.lins.append(torch.nn.Linear(out_channels, hidden_channels))\n",
    "#         for _ in range(num_layers - 2):\n",
    "#             self.lins.append(torch.nn.Linear(hidden_channels, hidden_channels))\n",
    "#         self.lins.append(torch.nn.Linear(hidden_channels, 1))\n",
    "\n",
    "#         self.dropout = dropout\n",
    "\n",
    "#         # Decide the similarity function\n",
    "#         if sim == 'inner':\n",
    "#             self.similarity = lambda x_i, x_j: (x_i * x_j).sum(dim=-1)\n",
    "#         elif sim == 'cosine':\n",
    "#             self.similarity = lambda x_i, x_j: F.cosine_similarity(x_i, x_j, dim=-1)\n",
    "\n",
    "# #     def reset_parameters(self):\n",
    "# #         for conv in self.convs:\n",
    "# #             conv.reset_parameters()\n",
    "# #         for lin in self.lins:\n",
    "# #             lin.reset_parameters()\n",
    "\n",
    "#     def encode(self, x, edge_index):\n",
    "#         # Pass data through GCN layers\n",
    "#         for conv in self.convs[:-1]:\n",
    "#             x = conv(x, edge_index).relu()\n",
    "#             x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "#         x = self.convs[-1](x, edge_index)\n",
    "#         return x\n",
    "\n",
    "#     def decode(self, z, edge_label_index):\n",
    "#         # Extract node embeddings for the given edge indices\n",
    "#         z_i, z_j = z[edge_label_index[0]], z[edge_label_index[1]]\n",
    "        \n",
    "#         # Apply link predictor layers\n",
    "#         x = self.similarity(z_i, z_j)\n",
    "        \n",
    "#         for lin in self.lins[:-1]:\n",
    "#             x = lin(x).relu()\n",
    "#             x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "#         x = self.lins[-1](x)\n",
    "        \n",
    "#         return torch.sigmoid(x) if self.sigmoid else x\n",
    "\n",
    "#     def forward(self, x, edge_index, edge_label_index):\n",
    "#         z = self.encode(x, edge_index)\n",
    "#         return self.decode(z, edge_label_index).view(-1)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b9231a5",
   "metadata": {},
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# from torch_sparse import SparseTensor\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.linkproppred import PygLinkPropPredDataset, Evaluator\n",
    "\n",
    "from logging import Logger\n",
    "\n",
    "# if args.use_sage:\n",
    "#     model = SAGE(data.num_features, args.hidden_channels,\n",
    "#                  args.hidden_channels, args.num_layers,\n",
    "#                  args.dropout).to(device)\n",
    "# else:\n",
    "#     model = GCN(data.num_features, args.hidden_channels,\n",
    "#                 args.hidden_channels, args.num_layers,\n",
    "#                 args.dropout).to(device)\n",
    "\n",
    "hidden_channels = 128\n",
    "dropout = 0.0\n",
    "num_layers = 2\n",
    "log_steps = 1\n",
    "batch_size = 64 * 1024\n",
    "lr = 0.001\n",
    "epochs = 400\n",
    "eval_steps = 50\n",
    "runs = 1\n",
    "\n",
    "# model = GCN_OGB(in_channels=data.num_features, hidden_channels=hidden_channels, \n",
    "#                 out_channels=64, num_layers=num_layers, dropout=dropout).to(device)\n",
    "\n",
    "# predictor = LinkPredictor(in_channels=hidden_channels, hidden_channels=hidden_channels, \n",
    "#                           out_channels=1, num_layers=num_layers, dropout=dropout).to(device)\n",
    "\n",
    "\n",
    "model = GCN_OGB(data.num_features, hidden_channels,\n",
    "                hidden_channels, num_layers,\n",
    "                dropout).to(device)\n",
    "\n",
    "predictor = LinkPredictor(hidden_channels, hidden_channels, 1,\n",
    "                          num_layers, dropout).to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37005a36",
   "metadata": {},
   "source": [
    "evaluator = Evaluator(name='ogbl-collab')\n",
    "loggers = {\n",
    "    'Hits@10': Logger(runs),\n",
    "    'Hits@50': Logger(runs),\n",
    "    'Hits@100': Logger(runs),\n",
    "}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e6fc1c1",
   "metadata": {},
   "source": [
    "def train(model, predictor, data, split_edge, optimizer, batch_size):\n",
    "    model.train()\n",
    "    predictor.train()\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(data.x.device)\n",
    "\n",
    "    total_loss = total_examples = 0\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size,\n",
    "                           shuffle=True):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        h = model(data.x, data.adj_t)\n",
    "\n",
    "        edge = pos_train_edge[perm].t()\n",
    "\n",
    "        pos_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        pos_loss = -torch.log(pos_out + 1e-15).mean()\n",
    "\n",
    "        # Just do some trivial random sampling.\n",
    "        edge = torch.randint(0, data.num_nodes, edge.size(), dtype=torch.long,\n",
    "                             device=h.device)\n",
    "        neg_out = predictor(h[edge[0]], h[edge[1]])\n",
    "        neg_loss = -torch.log(1 - neg_out + 1e-15).mean()\n",
    "\n",
    "        loss = pos_loss + neg_loss\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        torch.nn.utils.clip_grad_norm_(predictor.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        num_examples = pos_out.size(0)\n",
    "        total_loss += loss.item() * num_examples\n",
    "        total_examples += num_examples\n",
    "\n",
    "    return total_loss / total_examples\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, predictor, data, split_edge, evaluator, batch_size):\n",
    "    model.eval()\n",
    "    predictor.eval()\n",
    "\n",
    "    h = model(data.x, data.adj_t)\n",
    "\n",
    "    pos_train_edge = split_edge['train']['edge'].to(h.device)\n",
    "    pos_valid_edge = split_edge['valid']['edge'].to(h.device)\n",
    "    neg_valid_edge = split_edge['valid']['edge_neg'].to(h.device)\n",
    "    pos_test_edge = split_edge['test']['edge'].to(h.device)\n",
    "    neg_test_edge = split_edge['test']['edge_neg'].to(h.device)\n",
    "\n",
    "    pos_train_preds = []\n",
    "    for perm in DataLoader(range(pos_train_edge.size(0)), batch_size):\n",
    "        edge = pos_train_edge[perm].t()\n",
    "        pos_train_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_train_pred = torch.cat(pos_train_preds, dim=0)\n",
    "\n",
    "    pos_valid_preds = []\n",
    "    for perm in DataLoader(range(pos_valid_edge.size(0)), batch_size):\n",
    "        edge = pos_valid_edge[perm].t()\n",
    "        pos_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_valid_pred = torch.cat(pos_valid_preds, dim=0)\n",
    "\n",
    "    neg_valid_preds = []\n",
    "    for perm in DataLoader(range(neg_valid_edge.size(0)), batch_size):\n",
    "        edge = neg_valid_edge[perm].t()\n",
    "        neg_valid_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_valid_pred = torch.cat(neg_valid_preds, dim=0)\n",
    "\n",
    "    h = model(data.x, data.full_adj_t)\n",
    "\n",
    "    pos_test_preds = []\n",
    "    for perm in DataLoader(range(pos_test_edge.size(0)), batch_size):\n",
    "        edge = pos_test_edge[perm].t()\n",
    "        pos_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    pos_test_pred = torch.cat(pos_test_preds, dim=0)\n",
    "\n",
    "    neg_test_preds = []\n",
    "    for perm in DataLoader(range(neg_test_edge.size(0)), batch_size):\n",
    "        edge = neg_test_edge[perm].t()\n",
    "        neg_test_preds += [predictor(h[edge[0]], h[edge[1]]).squeeze().cpu()]\n",
    "    neg_test_pred = torch.cat(neg_test_preds, dim=0)\n",
    "\n",
    "    results = {}\n",
    "    for K in [10, 50, 100]:\n",
    "        evaluator.K = K\n",
    "        train_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_train_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        valid_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_valid_pred,\n",
    "            'y_pred_neg': neg_valid_pred,\n",
    "        })[f'hits@{K}']\n",
    "        test_hits = evaluator.eval({\n",
    "            'y_pred_pos': pos_test_pred,\n",
    "            'y_pred_neg': neg_test_pred,\n",
    "        })[f'hits@{K}']\n",
    "\n",
    "        results[f'Hits@{K}'] = (train_hits, valid_hits, test_hits)\n",
    "\n",
    "    return results"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8becd6c7",
   "metadata": {},
   "source": [
    "for run in range(runs):\n",
    "    model.reset_parameters()\n",
    "    predictor.reset_parameters()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        list(model.parameters()) + list(predictor.parameters()),\n",
    "        lr=lr)\n",
    "\n",
    "    for epoch in range(1, 1 + epochs):\n",
    "        loss = train(model, predictor, data, split_edge, optimizer,\n",
    "                     batch_size)\n",
    "\n",
    "        if epoch % eval_steps == 0:\n",
    "            results = test(model, predictor, data, split_edge, evaluator,\n",
    "                           batch_size)\n",
    "            for key, result in results.items():\n",
    "                print(key, result)\n",
    "#                 loggers[key].add_result(run, result)\n",
    "\n",
    "            if epoch % log_steps == 0:\n",
    "                for key, result in results.items():\n",
    "                    train_hits, valid_hits, test_hits = result\n",
    "                    print(key)\n",
    "                    print(f'Run: {run + 1:02d}, '\n",
    "                          f'Epoch: {epoch:02d}, '\n",
    "                          f'Loss: {loss:.4f}, '\n",
    "                          f'Train: {100 * train_hits:.2f}%, '\n",
    "                          f'Valid: {100 * valid_hits:.2f}%, '\n",
    "                          f'Test: {100 * test_hits:.2f}%')\n",
    "                print('---')\n",
    "\n",
    "#     for key in loggers.keys():\n",
    "#         print(key)\n",
    "#         loggers[key].print_statistics(run)\n",
    "\n",
    "# for key in loggers.keys():\n",
    "#     print(key)\n",
    "#     loggers[key].print_statistics()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27cb39df",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "if not osp.exists(osp.dirname(model_folder)):\n",
    "    os.makedirs(osp.dirname(model_folder))\n",
    "torch.save(model.state_dict(), f'{model_folder}/model.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfbf62",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c21fa1",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40e055a",
   "metadata": {},
   "source": [
    "seed_everything(seed)\n",
    "if model_name == 'gin':\n",
    "    model = LinkGIN(train_data.num_features, 128, 64, sim=decoder).to(device)\n",
    "    tot_epochs = 61\n",
    "if model_name == 'gcn':\n",
    "    model = LinkGCN(train_data.num_features, 128, 64, sim=decoder).to(device)\n",
    "    tot_epochs = 201\n",
    "if model_name == 'sage':\n",
    "    model = LinkSAGE(train_data.num_features, 128, 64, sim=decoder).to(device)\n",
    "    tot_epochs = 101\n",
    "if model_name == 'vgae':\n",
    "    if decoder == 'inner':\n",
    "        model = DeepVGAE(train_data.num_features, 128, 64, InnerProductDecoder()).to(device)\n",
    "    if decoder == 'cosine':\n",
    "        model = DeepVGAE(train_data.num_features, 128, 64, CosineDecoder()).to(device)\n",
    "    tot_epochs = 2001"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b50f8",
   "metadata": {},
   "source": [
    "if load_model:\n",
    "    model.load_state_dict(torch.load(f\"{model_folder}/model.pt\"))\n",
    "    model.eval()\n",
    "    print('Model loaded')\n",
    "    # val_auc = test(model, val_data)\n",
    "    test_auc, test_accuracy = test(model, test_data)\n",
    "    # print(f'Val auc: {val_auc:.4f}, Test auc: {test_auc:.4f}')\n",
    "    print(f'Test auc: {test_auc:.4f}, Test accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "else:\n",
    "    seed_everything(0)\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "    for epoch in range(1, tot_epochs):\n",
    "        loss = train(model, optimizer, train_data)\n",
    "        if epoch % 20 == 0:\n",
    "            if model_name == 'vgae':\n",
    "                # val_auc = test(model, train_data, val_data)\n",
    "                test_auc, test_accuracy = test(model, train_data, test_data)\n",
    "            else:\n",
    "                # val_auc = test(model, val_data)\n",
    "                test_auc, test_accuracy = test(model, test_data)\n",
    "            # print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "            #       f'Test: {test_auc:.4f}')\n",
    "            print(\n",
    "                f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Test auc: {test_auc:.4f}, Test accuracy: {test_accuracy:.4f}')\n",
    "    if not osp.exists(osp.dirname(model_folder)):\n",
    "        os.makedirs(osp.dirname(model_folder))\n",
    "    torch.save(model.state_dict(), f'{model_folder}/model.pt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7121cdb-f8a5-4ff7-bb46-061c094b6bd0",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7654e3ec-9548-4b1d-8082-0fc69a3189a7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f6b8e3-c522-4329-aba1-fdc1b3b3dbb3",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4691006d-a74a-482b-b23f-7b49a0de5bd7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8505eb67-72a8-45fd-ab4f-43175b49eb74",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322df2d7",
   "metadata": {},
   "source": [
    "# Take the first 100 examples.\n",
    "# edge_label_index is the edge that is to be predicted\n",
    "metric_list = []\n",
    "\n",
    "# select random edges\n",
    "selected_nodes_random_seed = 42\n",
    "num_selected_query_edges = 100\n",
    "\n",
    "# select edges with positive labels, and sample the num we need\n",
    "# TODO: val_data -> test_data\n",
    "positive_idx = (test_data.edge_label == torch.ones(test_data.edge_label.shape)).nonzero().flatten().numpy()\n",
    "print('The number of positive edges: ', len(positive_idx))\n",
    "# num_selected_query_edges = min(num_selected_query_edges, len(positive_idx))\n",
    "\n",
    "if num_selected_query_edges > len(positive_idx):\n",
    "    num_selected_query_edges = len(positive_idx)\n",
    "\n",
    "# TODO: could still result in the problem of negative prediction despite the positive label\n",
    "np.random.seed(selected_nodes_random_seed)\n",
    "selected_edge_pair_idx = np.random.choice(positive_idx, num_selected_query_edges, replace=False)\n",
    "print('Selected edges index: ', selected_edge_pair_idx)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc4240",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa0c802",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0a86f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a9c795",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b9b30",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aae888d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4892999",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c6b4e6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151ae613",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linkpred",
   "language": "python",
   "name": "linkpred"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
